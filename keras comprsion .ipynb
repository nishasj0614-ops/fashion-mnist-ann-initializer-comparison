import numpy as np
import matplotlib.pyplot as plt
from sklearn.metrics import confusion_matrix
from tensorflow import keras
from tensorflow.keras import layers
from tensorflow.keras.initializers import GlorotUniform, HeNormal, LecunNormal

# -------------------------------------------------
# 1. Load Dataset
# -------------------------------------------------
(x_train, y_train), (x_test, y_test) = keras.datasets.fashion_mnist.load_data()

x_train = x_train / 255.0
x_test = x_test / 255.0

# -------------------------------------------------
# 2. Glorot Model
# -------------------------------------------------
model_glorot = keras.Sequential([
    layers.Flatten(input_shape=(28, 28)),
    layers.Dense(256, activation='relu', kernel_initializer=GlorotUniform()),
    layers.Dense(128, activation='relu', kernel_initializer=GlorotUniform()),
    layers.Dense(10, activation='softmax')
])

model_glorot.compile(optimizer='adam',
                     loss='sparse_categorical_crossentropy',
                     metrics=['accuracy'])

history_glorot = model_glorot.fit(
    x_train, y_train,
    epochs=20,
    batch_size=128,
    validation_split=0.2,
    verbose=1
)

# -------------------------------------------------
# 3. He Normal Model
# -------------------------------------------------
model_he = keras.Sequential([
    layers.Flatten(input_shape=(28, 28)),
    layers.Dense(256, activation='relu', kernel_initializer=HeNormal()),
    layers.Dense(128, activation='relu', kernel_initializer=HeNormal()),
    layers.Dense(10, activation='softmax')
])

model_he.compile(optimizer='adam',
                 loss='sparse_categorical_crossentropy',
                 metrics=['accuracy'])

history_he = model_he.fit(
    x_train, y_train,
    epochs=20,
    batch_size=128,
    validation_split=0.2,
    verbose=1
)

# -------------------------------------------------
# 4. LeCun Model
# -------------------------------------------------
model_lecun = keras.Sequential([
    layers.Flatten(input_shape=(28, 28)),
    layers.Dense(256, activation='relu', kernel_initializer=LecunNormal()),
    layers.Dense(128, activation='relu', kernel_initializer=LecunNormal()),
    layers.Dense(10, activation='softmax')
])

model_lecun.compile(optimizer='adam',
                    loss='sparse_categorical_crossentropy',
                    metrics=['accuracy'])

history_lecun = model_lecun.fit(
    x_train, y_train,
    epochs=20,
    batch_size=128,
    validation_split=0.2,
    verbose=1
)

# -------------------------------------------------
# 5. Evaluate Models
# -------------------------------------------------
loss_g, acc_g = model_glorot.evaluate(x_test, y_test, verbose=0)
loss_h, acc_h = model_he.evaluate(x_test, y_test, verbose=0)
loss_l, acc_l = model_lecun.evaluate(x_test, y_test, verbose=0)

print("\nModel Evaluation Results")
print("----------------------------------")
print(f"Glorot   -> Loss: {loss_g:.4f}, Accuracy: {acc_g:.4f}")
print(f"He Normal-> Loss: {loss_h:.4f}, Accuracy: {acc_h:.4f}")
print(f"LeCun    -> Loss: {loss_l:.4f}, Accuracy: {acc_l:.4f}")
print("----------------------------------")

# -------------------------------------------------
# 6. Save Models
# -------------------------------------------------
model_glorot.save("glorot_model.keras")
model_he.save("he_normal_model.keras")
model_lecun.save("lecun_model.keras")

# -------------------------------------------------
# 7. Accuracy Bar Chart
# -------------------------------------------------
initializers = ["Glorot", "He Normal", "LeCun"]
accuracies = [acc_g, acc_h, acc_l]

plt.figure()
plt.bar(initializers, accuracies)
plt.title("Accuracy Comparison")
plt.ylabel("Accuracy")

for i in range(len(accuracies)):
    plt.text(i, accuracies[i], f"{accuracies[i]:.3f}", ha='center')

plt.show()

# -------------------------------------------------
# 8. Loss Bar Chart
# -------------------------------------------------
losses = [loss_g, loss_h, loss_l]

plt.figure()
plt.bar(initializers, losses)
plt.title("Loss Comparison")
plt.ylabel("Loss")

for i in range(len(losses)):
    plt.text(i, losses[i], f"{losses[i]:.3f}", ha='center')

plt.show()

# -------------------------------------------------
# 9. Train vs Validation Accuracy
# -------------------------------------------------
train_acc = [
    history_glorot.history['accuracy'][-1],
    history_he.history['accuracy'][-1],
    history_lecun.history['accuracy'][-1]
]

val_acc = [
    history_glorot.history['val_accuracy'][-1],
    history_he.history['val_accuracy'][-1],
    history_lecun.history['val_accuracy'][-1]
]

x = np.arange(len(initializers))
width = 0.35

plt.figure()
plt.bar(x - width/2, train_acc, width, label="Train Accuracy")
plt.bar(x + width/2, val_acc, width, label="Validation Accuracy")

plt.xticks(x, initializers)
plt.ylabel("Accuracy")
plt.title("Train vs Validation Accuracy")
plt.legend()
plt.show()

# -------------------------------------------------
# 10. Confusion Matrices with Custom Colors
# -------------------------------------------------
y_pred_glorot = np.argmax(model_glorot.predict(x_test), axis=1)
y_pred_he = np.argmax(model_he.predict(x_test), axis=1)
y_pred_lecun = np.argmax(model_lecun.predict(x_test), axis=1)

cm_glorot = confusion_matrix(y_test, y_pred_glorot)
cm_he = confusion_matrix(y_test, y_pred_he)
cm_lecun = confusion_matrix(y_test, y_pred_lecun)

plt.figure(figsize=(15,5))

# Grey - Glorot
plt.subplot(1,3,1)
plt.imshow(cm_glorot, cmap='gray')
plt.title("Glorot (Grey)")
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.colorbar()

# Green - He Normal
plt.subplot(1,3,2)
plt.imshow(cm_he, cmap='Greens')
plt.title("He Normal (Green)")
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.colorbar()

# Pink - LeCun
plt.subplot(1,3,3)
plt.imshow(cm_lecun, cmap='pink')
plt.title("LeCun (Pink)")
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.colorbar()

plt.tight_layout()
plt.show()
